{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW05.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install segmentation_models_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l7RvhuZIeIc",
        "outputId": "e8b6d14d-2516-406f-93aa-8679f52a6736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.7.4)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.4.12)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.6.3)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.62.3)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzecu7ooxB7v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8C9MeHT93Bvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede18074-b980-4b9e-823a-8a68607055fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.\tНеобходимо скачать и подготовить датасет https://www.kaggle.com/olekslu/makeup-lips-segmentation-28k-samples/notebooks для обучения модели на сегментацию губ (обратите внимание, что сегментация подразумевает уже два класса: фон и губы)."
      ],
      "metadata": {
        "id": "h47-tN1PyuRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "photos = []\n",
        "lips = []\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/set-lipstick-original'):\n",
        "    for name in files:\n",
        "        f = os.path.join(root, name)\n",
        "        if 'photos' in f:\n",
        "            photos.append(f)\n",
        "        elif 'lips' in f:\n",
        "            lips.append(f)\n",
        "        else:\n",
        "            break"
      ],
      "metadata": {
        "id": "8adjVIDoyvUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(photos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxsw8mzUECsR",
        "outputId": "b6a8bf80-f6ab-4a87-e716-f70befff85dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28604"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqL-Q9BBEI_C",
        "outputId": "da4ee992-7755-4247-e298-9d69738a1c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28586"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "photos = photos[:5000]\n",
        "lips = lips[:5000]"
      ],
      "metadata": {
        "id": "lpEZ0A_fF2JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'photos': photos, 'lips': lips})\n",
        "# Отсортируем  датафрейм по значениям\n",
        "df.sort_values(by='photos',inplace=True)\n",
        "# Используем функцию,\n",
        "# лагодаря которой индексация значений \n",
        "# будет начинаться с 0.\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "# Выведем первые ять значений нашего датафрейма\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYvy-zeX8GFg",
        "outputId": "126b0d81-bbd6-4997-d647-75aa69c7f752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              photos                                               lips\n",
            "0  /content/drive/MyDrive/set-lipstick-original/p...  /content/drive/MyDrive/set-lipstick-original/l...\n",
            "1  /content/drive/MyDrive/set-lipstick-original/p...  /content/drive/MyDrive/set-lipstick-original/l...\n",
            "2  /content/drive/MyDrive/set-lipstick-original/p...  /content/drive/MyDrive/set-lipstick-original/l...\n",
            "3  /content/drive/MyDrive/set-lipstick-original/p...  /content/drive/MyDrive/set-lipstick-original/l...\n",
            "4  /content/drive/MyDrive/set-lipstick-original/p...  /content/drive/MyDrive/set-lipstick-original/l...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetFromImages(Dataset):\n",
        "    def __init__(self, data_info):\n",
        "        self.data_info = data_info\n",
        "        self.image_arr = self.data_info.iloc[:,0]\n",
        "        self.label_arr = self.data_info.iloc[:,1]\n",
        "        self.data_len = len(self.data_info.index)\n",
        "    def __getitem__(self, index):\n",
        "        img = np.asarray(Image.open(self.image_arr[index])).astype('float')\n",
        "        img = torch.as_tensor(img)/255\n",
        "        img = img.unsqueeze(0).permute(0,3,1,2)\n",
        "        img = F.interpolate(input=img, size=256, align_corners=False, mode='bicubic')\n",
        "        \n",
        "        lab = np.asarray(plt.imread(self.label_arr[index])).astype('float')[:,:,0]*255\n",
        "        lab = torch.as_tensor(lab).unsqueeze(0)\n",
        "        lab = lab.unsqueeze(0)\n",
        "        lab = F.interpolate(input=lab, size=256, mode='nearest')\n",
        "        \n",
        "        return (img.float(), lab.float())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ],
      "metadata": {
        "id": "LJ02nHNuID7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 70 % в тренировочную выборку, 30 - в тестовую\n",
        "X_train, X_test = train_test_split(df,test_size=0.3)\n",
        "\n",
        "# Упорядочиваем индексацию\n",
        "X_train.reset_index(drop=True,inplace=True)\n",
        "X_test.reset_index(drop=True,inplace=True)\n",
        "\n",
        "# Оборачиваем каждую выборку в наш кастомный датасет\n",
        "train_data = CustomDatasetFromImages(X_train)\n",
        "test_data = CustomDatasetFromImages(X_test)"
      ],
      "metadata": {
        "id": "zWDcaTxIIQwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = DataLoader(train_data,batch_size=8,shuffle=True)\n",
        "test_data_loader = DataLoader(test_data,batch_size=4,shuffle=False)"
      ],
      "metadata": {
        "id": "bxPu-UuuIUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_data_loader))\n",
        "print(data[0].mean(), data[0].std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kur1_SZsKWPP",
        "outputId": "18a9875a-e37c-450a-838f-cd18e13d2dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6719) tensor(0.2639)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "C8d9K8OpKY45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.\tИ затем обучить Модель на выбор из segmentation_models_pytorch"
      ],
      "metadata": {
        "id": "YvtK-CsFJKHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(output, target, weights=None, ignore_index=None):\n",
        "    \"\"\"\n",
        "    output : NxCxHxW Variable\n",
        "    target :  NxHxW LongTensor\n",
        "    weights : C FloatTensor\n",
        "    ignore_index : int index to ignore from loss\n",
        "    \"\"\"\n",
        "    eps = 0.0001\n",
        "\n",
        "    output = output.float().exp()\n",
        "    target = target.type(torch.int64)\n",
        "    encoded_target = output.detach() * 0\n",
        "    if ignore_index is not None:\n",
        "        mask = target == ignore_index\n",
        "        target = target.clone()\n",
        "        target[mask] = 0\n",
        "        encoded_target.scatter_(1, target.unsqueeze(1), 1)\n",
        "        mask = mask.unsqueeze(1).expand_as(encoded_target)\n",
        "        encoded_target[mask] = 0\n",
        "    else:\n",
        "        encoded_target.scatter_(1, target.unsqueeze(1), 1)\n",
        "\n",
        "    if weights is None:\n",
        "        weights = 1\n",
        "\n",
        "    intersection = output * encoded_target\n",
        "    numerator = 2 * intersection.sum(0).sum(1).sum(1)\n",
        "    denominator = output + encoded_target\n",
        "\n",
        "    if ignore_index is not None:\n",
        "        denominator[mask] = 0\n",
        "    denominator = denominator.sum(0).sum(1).sum(1) + eps\n",
        "    loss_per_channel = weights * (1 - (numerator / denominator))\n",
        "\n",
        "    return loss_per_channel.sum() / output.size(1)"
      ],
      "metadata": {
        "id": "7hFfFujwKiqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        smooth =1\n",
        "        num = targets.size(0)\n",
        "        probs = logits\n",
        "        m1 = probs.view(num, -1)\n",
        "        m2 = targets.view(num, -1)\n",
        "        intersection = (m1 * m2)\n",
        "\n",
        "        score =(2. * intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
        "        #print(score.sum())\n",
        "        score =1 - score.sum() / num\n",
        "        return score\n",
        "    # This function has only a single output, so it gets only one gradient\n",
        "    def backward(self, grad_output):\n",
        "\n",
        "        input, target = self.saved_variables\n",
        "        grad_input = grad_target = None\n",
        "\n",
        "        if self.needs_input_grad[0]:\n",
        "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
        "                         / (self.union * self.union)\n",
        "        if self.needs_input_grad[1]:\n",
        "            grad_target = None\n",
        "\n",
        "        return grad_input, grad_target"
      ],
      "metadata": {
        "id": "WMS9U1HaO-lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "d9F3yYuyJzPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmodel = smp.Unet('resnet34', classes=2, activation='softmax')\n",
        "#segmodel = smp.Unet('resnet34', classes=1, activation='softmax').to(device)\n"
      ],
      "metadata": {
        "id": "5P9EFGBVKKD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(segmodel.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "ShsJdDgnJrwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step_losses = []\n",
        "epoch_losses = []\n",
        "\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    epoch_loss = []\n",
        "    t = 0\n",
        "    time1 = time.time()\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        #inputs = inputs.cuda()\n",
        "        #labels = labels.cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "  \n",
        "        # forward + backward + optimize\n",
        "        outputs = segmodel(inputs[0])\n",
        "        loss = dice_loss(outputs,labels[0,0,:,:,:])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        epoch_loss.append(loss.item())\n",
        "        t+=1\n",
        "        if t % 5000 == 4999:    # print every 5000 mini-batches\n",
        "            print(f'Epoch: {epoch}, batchcount: {t}, avg. loss for last 5000 images: {running_loss/5000}')\n",
        "    time2 = time.time()\n",
        "    print(f'Epoch {epoch+1}, loss: ',np.mean(epoch_loss),f' time = {time2-time1} sec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "hXJ1-8-KIXkU",
        "outputId": "f0f754d0-eb2e-4bb2-c49d-aa5ddff9e0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/base/modules.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.activation(x)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2143df198717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-e0b30fc5f40b>\u001b[0m in \u001b[0;36mdice_loss\u001b[0;34m(output, target, weights, ignore_index)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mencoded_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mencoded_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: index 3 is out of bounds for dimension 1 with size 2"
          ]
        }
      ]
    }
  ]
}